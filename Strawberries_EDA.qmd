---
title: "Strawberries"
author: "Ajay Krishnakumar"
date: 2023 Oct 23
format: pdf
engine: knitr
---

## Introduction: The data, the motivations

When was the last time you looked at your strawberries - not just a cursory examination before you ate them - but when you really looked? At the labels, at the warnings and cautions and USDA certifications and the chemicals they spray on them? I had certainly never considered any of those factors until this assignment, until we were told that perhaps this was something to look into, until Haviland Wright painted for us the extent to which strawberries are not to be trusted.

-   What sort of chemicals are being used on strawberries?
-   How hazardous are these chemicals?
-   Where are these chemicals used most?

Considering the consistent placing of Strawberries on the 'Dirty Dozen' list(https://www.ewg.org/foodnews/dirty-dozen.php), these some  questions we should be thinking about. As consumers we should be concerned about the extensive use of pesticide in daily foods. As human beings with an instinct for self-preservation, we should be concerned about the chemicals we are putting in our bodies. So what can the data tell us? How alarmed should we be? I'll try to answer that first question. The second is left as an exercise for the reader.

Before getting into the weeds with the pesticides, we shall also look at data on market information. Is there anything we can say about prices of strawberries, their end uses? It would certainly be a useful lens with which to color our later analysis.

The data itself is from the USDA NASS database, cleaned through much effort on Haviland's part(though perhaps not one hundredth of the effort we should put into cleaning our strawberries). It is this data - collected by survey instead of census and focusing on non organic strawberries - that serves as the jumping off point for what follows.

## Data Cleaning and Organization

The first order of business is to split the data that remains from the earlier cleaning into market data and chemical data. This is done thus:

```{r}

#Loading the libraries we shall need
library(knitr)
library(tidyverse)
library(stringr)
library(ggplot2)
library("Hmisc")

strwb_survey<- read.csv("strwb_survey.csv", header = TRUE)

#Extracting the data relevant to chemicals using the Pesticide or Market Column

strwb_survey_c<- strwb_survey |> filter(Pesticide_or_Market ==
                                          " BEARING - APPLICATIONS")
strwb_mkt<- strwb_survey |> filter(Pesticide_or_Market != 
                                     " BEARING - APPLICATIONS")
```

The data being read in here is the data that Haviland cleaned, with a couple columns named by me and written into a csv file.

#### Cleaning Market Data

Let us consider first, the market data. A view statement shows us what it looks like and what needs to be done to clean it. I won't print that View statement here but suffice it to say there are changes that can be made here to clean the data. First, regarding the column I have named Price or Weight: It transpires that this is hardly an appropriate name.

```{r}
strwb_mkt |> distinct(Price_or_Weight.)

strwb_mkt <- strwb_mkt |> rename(PriceProduction = Price_or_Weight.)
```

We can see that this column takes three distinct values: "PRICE RECEIVED", NA and "PRODUCTION". I have renamed this column more sensibly above. While I have called it PriceProduction, it is important to note that the NA values aren't just dead space in every case. In the case of the chemical subset of the data, this should rightly be NA. But this dataset doesn't have the chemicals data. So what about the NAs here?

A quick examination tells us that Price or Production can be interpolated from one of the next two columns.

What about the name of the Pesticide or Market column? This seemed fitting when I used the column to subset chemical and market data. We can check distinct Domain Categories to confirm that this is a valid way to subset our data. But in the market subset, what information does this column now convey?

The code below deals with both these issues.

```{r}

#Getting Price or Production values
strwb_mkt$PriceProduction<-ifelse(is.na(strwb_mkt$PriceProduction)==FALSE,
                                   strwb_mkt$PriceProduction,
  ifelse(str_detect(strwb_mkt$Pesticide_or_Market,"PRODUCTION")==TRUE |
    str_detect(strwb_mkt$Measurement_Unit,"PRODUCTION")==TRUE,"PRODUCTION",
  ifelse(str_detect(strwb_mkt$Pesticide_or_Market,"PRICE RECEIVED")==TRUE |       str_detect(strwb_mkt$Measurement_Unit,"PRICE RECEIVED")==TRUE,
         "PRICE RECEIVED",strwb_mkt$PriceProduction)))

#Changing the name of Pesticide or Market

strwb_mkt<- strwb_mkt |> rename(
                                Purpose = Pesticide_or_Market
)

```

But now we see the Purpose column doesn't always have purpose. Sometimes it contains what is very clearly the Measurement Unit, while the Measurement Unit itself is NA. Let's fix this too.

```{r}
strwb_mkt$Measurement_Unit<- ifelse(is.na(strwb_mkt$Measurement_Unit),
                                strwb_mkt$Purpose,strwb_mkt$Measurement_Unit)
strwb_mkt$Purpose<- str_replace(strwb_mkt$Purpose,"- PRICE RECEIVED","")
strwb_mkt$Purpose<- str_replace(strwb_mkt$Purpose,"- PRODUCTION","")

strwb_mkt$Purpose<- ifelse(str_detect(strwb_mkt$Purpose,"MEASURED")==TRUE, 
                           "AGGREGATE",
                           strwb_mkt$Purpose)

strwb_mkt$Aggregate_type<- ifelse(strwb_mkt$Purpose == "Aggregate", 
                                  strwb_mkt$Measurement_Unit,
                                  strwb_mkt$Aggregate_type)
```

Measurement Unit doesn't seem to always represent measurement unit and in fact probably contains aggregate type instead - for example where it says "Production Utilization". Let's fix that:

```{r}

a<- strwb_mkt$Measurement_Unit[which(str_detect(strwb_mkt$Measurement_Unit,
                                                "MEASURED")==FALSE)]
b<- strwb_mkt$Aggregate_type[which(str_detect(strwb_mkt$Measurement_Unit,
                                              "MEASURED")==FALSE)]

strwb_mkt$Aggregate_type[which(str_detect(strwb_mkt$Measurement_Unit,
                                          "MEASURED")==FALSE)]<- a
strwb_mkt$Measurement_Unit[which(str_detect(strwb_mkt$Measurement_Unit,
                                            "MEASURED")==FALSE)]<- b

#Casting all non numeric values as NA
strwb_mkt$Value<- suppressWarnings(as.numeric(strwb_mkt$Value))
```

That's the market data cleaned.

#### Cleaning Chemical Data

We start by extracting all the chemical information we can from the data we have. This is stored in the Domain and Domain Category columns.

```{r}
#Getting the Chemical Type and putting it into its own column
strwb_survey_chem1 <- strwb_survey_c |> mutate(`Chemical Type` = 
                        str_sub(Domain,str_locate(Domain,"CHEMICAL,")[,2]+1,),
                                             .after= Domain.Category)

#Extracting Chemical Name into a column
strwb_survey_chem1<- strwb_survey_chem1 |> mutate(`Chemical Name`=
                                            str_sub(Domain.Category,
                                          str_locate(Domain.Category,":")[,2]+3,
                                        str_locate(Domain.Category,"=")[,1]-2),
                                                  .after = `Chemical Type`)
#Extracting Chemical ID into a column
strwb_survey_chem1<- strwb_survey_chem1 |> mutate(`Chemical ID`=
                          str_sub(Domain.Category,-7), .after= `Chemical Name`)

strwb_survey_chem1$`Chemical ID`<-
  str_sub(strwb_survey_chem1$`Chemical ID`,1,-2)

strwb_survey_chem1$`Chemical ID`<- ifelse(strwb_survey_chem1$Domain=="TOTAL",
                                          NA,strwb_survey_chem1$`Chemical ID`)

strwb_survey_chem1$`Chemical ID`<- 
  ifelse(str_detect(strwb_survey_chem1$Domain.Category,"TOTAL")==TRUE,NA,
                                          strwb_survey_chem1$`Chemical ID`)

strwb_survey_chem1$`Chemical ID`<- 
  str_replace(strwb_survey_chem1$`Chemical ID`,"=","")

strwb_survey_chem1$`Chemical ID`<- 
  str_trim(strwb_survey_chem1$`Chemical ID`, side = 'both')

strwb_survey_chem<- strwb_survey_chem1
```

Now we will use the PC codes we've extracted and placed in Chemical ID and use the EPA Pesticide Chemical Search (https://ordspub.epa.gov/ords/pesticides/f?p=chemicalsearch:1) to find CAS codes where we can.

```{r}
#Creating a list of distinct chemical names in the dataset, their ids
chemical_list<- strwb_survey_chem |> filter(is.na(`Chemical Name`)!=TRUE) |>
                distinct(`Chemical Name`,.keep_all = TRUE)|> 
                select(`Chemical Name`,`Chemical ID`)

#Finding the CAS numbers corresponding to each chemical:

CAS_no<-c("131860-33-8","","","","","","1219521-95-5","1303-96-4","188425-85-6",
     "","133-06-2","20543-04-8","180409-60-3","121552-61-2","119446-68-3",
     "126833-17-8","131341-86-1","658066-35-4","907204-31-3","39148-24-8",
       "875915-78-9","70630-17-0","13492-26-7","88671-89-0","183675-82-3",
       "146659-78-1","	298-14-6","60207-90-1","	175013-18-0","53112-28-0",
        "878790-59-1","","7704-34-9","112281-77-3","23564-05-8","137-26-8",
       "141517-21-7","68694-11-1","128639-02-1","103361-09-7","38641-94-0",
       "70901-12-1","15299-99-7","42874-03-3","1910-42-5","	40487-42-1",
       "71751-41-2","57960-19-7","135410-20-7","108168-76-9","63428-82-0",
       "149877-41-8","82657-04-3","68038-71-1","68038-71-1","68038-71-1",
      "68038-71-1","68038-71-1","69327-76-0","","120962-03-0","500008-45-7",
   "","736994-63-1","400882-07-7","333-41-5","153233-91-1","13356-08-6",
        "39515-41-8","134098-61-6","158062-67-0","951659-40-8","","78587-05-0",
    "138261-41-3","121-75-5","161050-58-4","300-76-5","8002-65-1","947173-77-5",
    "116714-46-6","64742-89-8","51-03-6","67701-09-1","8003-34-7","96489-71-3",
     "95737-68-1","935545-74-7","131929-60-7","283594-90-1","153719-23-4",
     "135158-54-2","334-48-5","124-07-2","8023-77-6","76-06-2","542-75-6",
  "76674-21-0","8000-78-0","7722-84-1","10045-86-0","137-41-7","8012-95-1",
    "","79-21-0","1312-76-1","","","1228284-64-7","99129-21-2","14215-52-2",
  "87674-68-8","81406-37-3","100784-20-1","145701-23-1","63-25-2","120928-09-8",
  "946578-00-3","525-79-1","16672-87-0","133-32-4","","20427-59-2","67892-31-3",
  "77182-82-2","	122836-35-5","2921-88-2","8001-22-7","1315501-18-8","","",
  "68038-71-1","","108-62-3","137-42-8","","1332-65-6","2439-10-3","66332-96-5",
    "2008-39-1","32341-80-3","52315-07-8","68424-85-1","32426-11-2","5538-94-3",
   "7173-51-5","36734-19-7","155569-91-8","91465-08-6","203313-25-1","57-06-7",
     "624-92-0","1317-39-1","63718-65-0","272451-65-7","74-83-9","1897-45-6",
   "120116-88-3","8018-01-7","115-29-7","404-86-4","",	"57754-85-5","122-34-9",
       "5902-51-2","15708-41-5","81777-89-1")

chemical_list$CAS_no<- CAS_no

```

Now, these CAS codes are cross-referenced with the WHO's Classification of Pesticides by Hazard and Guidelines to Classification(https://iris.who.int/bitstream/handle/10665/332193/9789240005662-eng.pdf?sequence=1), pages 72 onwards. This gives us the following:

```{r}
#Reading in UN information on hazards by CAS number
library(readxl)
hazards <- read_xlsx("WHO_codes.xlsx")
hazards$CAS_no <- str_trim(str_sub(hazards$CAS,1,
                                   str_locate(hazards$CAS," ")[,2]),"both")

codes<- hazards$CAS_no

hazards$Toxicity<- str_sub(hazards$CAS, str_locate(hazards$CAS,
                    fixed(hazards$CAS_no))[,2],)

hazards$Toxicity <- str_match(hazards$Toxicity, " \\s*(.*?)\\s* ")[,2]

hazards<- hazards |> select(-CAS)

hazards$Hazard <- ifelse(hazards$Toxicity=="Ia","Extremely hazardous",
                  ifelse(hazards$Toxicity=="Ib","Highly hazardous",
                  ifelse(hazards$Toxicity=="II","Moderately hazardous",
                  ifelse(hazards$Toxicity=="III", "Slightly hazardous",
                  ifelse(hazards$Toxicity =="U","Not acutely hazardous",
                  ifelse(hazards$Toxicity=="FM","Fumigant","Obsolete"))))))

hazard_info<- merge(x =chemical_list,y=hazards,by="CAS_no",
                    x.chemical_list=TRUE)

#adding in a few chemicals whose codes were missing by hand

hazard_info<-rbind(hazard_info,c("20543-04-8","COPPER OCTANOATE","	
23306","U","Not acutely hazardous"))

hazard_info<-rbind(hazard_info,c("2180409-60-3","	
CYFLUFENAMID","555550","U","Not acutely hazardous"))

hazard_info<-rbind(hazard_info,c("121552-61-2","CYPRODINIL","	
288202","U","Not acutely hazardous"))

hazard_info<-rbind(hazard_info,c("70630-17-0","	
MEFENOXAM","113502","III","Slightly hazardous"))

hazard_info<-rbind(hazard_info,c("","PAECILOMYCES FUMOSOR","115002","U",
                                 "Not acutely hazardous"))


strwb_chem_info<- merge(x=strwb_survey_chem,y=hazard_info, by= "Chemical Name", 
                        all.x=TRUE)

strwb_chem_info$Value <- suppressWarnings(as.numeric(strwb_chem_info$Value))
strwb_chem_info$Value <- ifelse(strwb_chem_info$Value == "	
(NA)", NA,strwb_chem_info$Value)
```

To prepare for EDA let's do a few more things to the chemical data.

```{r}
#We are going to filter our data set so we look only at those 
#entries for which we have hazard information

chem<- strwb_chem_info |> filter(is.na(Hazard)!=TRUE)

#Data with the aggregate type = AVG. What does AVG actually show us?

avg_chem <- chem |> filter(Aggregate_type==" AVG")
non_avg_chem <- chem |> filter(is.na(Aggregate_type)==TRUE)
```

A look at the two data frames created as above gives us interesting information. It would appear that the 'non_avg-chem' data shows the total weight in pounds of a particular fertilizer applied in that particular Year. The 'avg-chem' data looks at various 'average' data. I would contend that average is a little bit of a misnomer here and calling these 'per unit' data would be more informative. We have lb/acre/year, lb/acre/application and the 'number'

## Exploratory Data Analysis - Market Data

Preliminary Questions:

-   What strawberries are most expensive? Intuitively you'd expect fresh market strawberries to have the highest markup. Is this true?
-   How do prices vary across state?

```{r, echo=FALSE}
# There are a lot of NA values in this dataset. Let's remove them 
#and see what we get from the rest:
mkt_eda<- strwb_mkt |> filter(is.na(Value)==FALSE)

#Looking at prices per cwt:

prices<- mkt_eda |> filter( Measurement_Unit == " MEASURED IN $ / CWT") |>
  filter(Purpose != "AGGREGATE") |> 
  group_by(Purpose)

ggplot(prices, aes(Purpose, Value))+
  geom_violin(draw_quantiles = c(0.25,0.5,0.75))+
  labs(
title="Relative distributions of Fresh Market and Production Market strawberry prices",
    x="Market", y=" Price in $ / Hundredweight (lb)"
  )
  

```

We can tell from this graph that the overwhelming majority of fresh market strawberries are sold for significantly more than processing market strawberries. Just compare the median price per hundredweight(the middle lines in the violin plots). What's interesting is that the interquartile range for the two seems very similar at \$40/cwt. The minimum and maximum values for fresh market strawberries are miles apart however. This might be due to transportation costs or the mark-up at places like farmers markets, say.

What can we tell about how the difference in fresh market and processing varies between states?

```{r, echo=FALSE}
state_prices<- mkt_eda |> filter( Measurement_Unit == " MEASURED IN $ / CWT") |>
  filter(Purpose != "AGGREGATE") |> group_by(State)

#calcualte the difference between each row:

state_prices<- state_prices |> mutate(market_diff = 
  Value - lag(Value, default = Value[1])) |> select(Year, State, market_diff) 

rows <- seq(1,38)
diff_state_prices<- state_prices[rows%%2==0,]
diff_state_prices$market_diff<- abs(diff_state_prices$market_diff)
diff_state_prices$Year<- factor(diff_state_prices$Year)
  
ggplot(diff_state_prices, aes(State, market_diff, color = Year))+
  geom_point(size=3)+theme(axis.text.x = element_text(angle = 90, vjust = 1, 
                                                      hjust=1))+
  labs(title="Yearly Variations in Fresh Market vs Production Market Prices by State",
       x="State", y= "Price Difference\n Fresh market vs production market")
  



```

We can see that California, relative to other states is relatively consistent in the difference in price of fresh market and production market strawberries. It is also on the lower side. North Carolina has the largest variation in the difference.

What's also interesting here is how in 2016, east coast states observed a higher difference in price relative to west coast states.

What about yearly variations in these prices?

```{r, echo=FALSE}
g<-ggplot(data=prices, aes(Year, Value, color=Purpose))+
  geom_point()+stat_smooth()+
  labs(title="Yearly Variation in price difference between strawberry markets",
       x="Year",y="Price per Hundredweight")
suppressMessages(suppressWarnings(print(g)))
```

I'll begin the discussion of this graph with a caveat: There is a limited amount of information we can glean from this - this is reflected in the increasing area of the error 'shadow' around the line. In large part this is due to the dwindling number of points each consecutive year.

All the same, there is some information we can see. There is a decreasing trend in both prices but also a decrease in the distance between the smoothed regression lines.

In none of the years do any of the fresh market prices go beneath those of even the highest production market. The overlap of the shadows and the increase in its area towards the end might indicate that perhaps we might find a point or two like that if we had more data for the more recent years and if the trend shown in the graph is backed up by that data. That is certainly interesting. Were that to be true, what would drive that reversal of the dynamic of the two prices?

Maybe there's a world(not this world and not a world we can infer from the data above) where people buy fewer fresh strawberries. Why? Because who wants to eat chemically-tainted strawberries?

## Exploratory Data Analysis - Pesticides on Strawberries

Let's start by looking at the amount of each pesticide sprayed per year and per application. These tell us two different things. Per year tells us which pesticide is used the most. Per application gives some information about the relative efficacy of each pesticide.

Starting with per year. If we try and plot all of our pesticides, it becomes impossible to glean anything clear because of the sheer range of the data. There are a few pesticides that are used in small quantities.I have I have a hunch that those will turn up in the per application graph so we'll graph their use per year separately.

```{r, echo=FALSE}
years<- avg_chem |> filter(Measurement_Unit==" MEASURED IN LB / ACRE / YEAR") |>
  group_by(`Chemical Name`) |>  filter(Value>10)

years<- years |> filter(is.na(Value)==FALSE)
years$Year<- factor(years$Year) 

ggplot(years, aes(`Chemical Name` ,Value, color=Year))+ 
  geom_point(size=3)+
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)
        )+ 
  labs(title="Application of Pesticides in LB/Acre/Year - Value Greater than 10", x="Pesticide", y= "Amount applied in lb/acre/year")
```

What about for the pesticides with smaller values?

```{r, echo=FALSE}
years<- avg_chem |> filter(Measurement_Unit==" MEASURED IN LB / ACRE / YEAR") |>
  group_by(`Chemical Name`) |>  filter(Value<10&Value>0.3)

years<- years |> filter(is.na(Value)==FALSE)
years$Year<- factor(years$Year) 

ggplot(years, aes(`Chemical Name` ,Value, color=Year))+ 
  geom_point(size=3)+
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)
        )+ 
  labs(title="Application of Pesticides in LB/Acre/Year: 0.3< Value<10 ", x="Pesticide", y= "Amount applied in lb/acre/year")
```

Now for the most interesting of this series of plots, the chemicals(and there are a lot of them) which are applied in smaller quantities per acre per year. I've gotten rid of colors here so we can see the variability in points more easily without being distracted

```{r, echo=FALSE}
years<- avg_chem |> filter(Measurement_Unit==" MEASURED IN LB / ACRE / YEAR") |>
  group_by(`Chemical Name`) |>  filter(Value<0.3)

years<- years |> filter(is.na(Value)==FALSE)
years$Year<- factor(years$Year) 


ggplot(years, aes(`Chemical Name` ,Value))+ 
  geom_point(size=3)+
  stat_summary(fun.data=mean_sdl, fun.args = list(mult=1), 
        geom="errorbar", color="orange", width=0.3)+
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)
        )+ 
  labs(title="Application of Pesticides in LB/Acre/Year: Value<0.3 ", x="Pesticide", y= "Amount applied in lb/acre/year")
```

So let's use the same chemicals as in the graph above but let's look at their quantity per application.

```{r, echo=FALSE}
applications<- avg_chem |> filter(`Chemical Name` %in% years$`Chemical Name`) |> 
  filter(Measurement_Unit==" MEASURED IN LB / ACRE / APPLICATION")

g<- ggplot(applications, aes(`Chemical Name` ,Value))+ 
  geom_point(size=3)+
  stat_summary(fun.data=mean_sdl, fun.args = list(mult=1), 
        geom="errorbar", color="orange", width=0.3)+
  theme(axis.text.x = element_text(angle = 90, vjust = 1, hjust=1)
        )+ 
  labs(title="Application of Pesticides in LB/Acre/Application ", x="Pesticide", y= "Amount applied in lb/acre/application")

suppressWarnings(print(g))
```

\`\`\`

This data shows that all these compounds are used in incredibly small quantities per application. The relative amount used per application is extremely similar to the relative differences in amount used per year. What does this tell us? Are these pesticides very effective at doing their job? I would say that the data shows that, given the information we have(we could confirm this with information on yields of strawberry crops sprayed with different quantities of each pesticide but that's beyond the scope of this report). So why are they effective? Could it be because they are toxic.

Before we look at that, its worth noting that the application of azoxystrobin has a large error bar because of one point where it was applied in a large quantity.


```{r, echo=FALSE}
pot_toxic_chemicals<- hazard_info |> filter(
  `Chemical Name` %in% years$`Chemical Name`)
ggplot(pot_toxic_chemicals, aes(Hazard))+
  geom_bar()+labs(
    title="Hazard for Chemicals applied in small amounts per application",
    y="Number")
```
So a decent number of these chemicals are either highly hazardous or moderately hazardous. More importantly only eight of them are not acutely hazardous. But this does put some paid to the theory that these would all be highly hazardous chemicals. Why don't we look at chemicals that are applied in large amounts. What is their toxicity like? 

```{r, echo=FALSE}
years<- avg_chem |> filter(Measurement_Unit==" MEASURED IN LB / ACRE / YEAR") |>
  group_by(`Chemical Name`) |>  filter(Value<10&Value>0.3)

years<- years |> filter(is.na(Value)==FALSE)
years$Year<- factor(years$Year)

big_apps<- hazard_info |> filter(
  `Chemical Name` %in% years$`Chemical Name`)

ggplot(big_apps, aes(Hazard))+
  geom_bar()+labs(
    title="Hazard for Chemicals applied in large amounts per application",
    y="Number")
```
This is interesting. It makes sense that a large number of these are not acutely hazardous. What this suggests is that the small number of severely hazardous chemicals applied is good because perhaps the large number of them are banned. All the same the large number of moderately hazardous chemicals applied is concerning. 

Another thing to think about that might bear future exploration: What kind of spectrum is moderately hazardous? We have moderately hazardous chemicals applied in large quantities and in small. Are some much more hazardous than others?

## Conculding Remarks

Not good news I'm afraid. Regardless of the happy news that severely hazardous chemicals are not frequently applied and not in large quantities, very many other toxic pesticides do seem to be applied to strawberry crops and some of them in large quantitites. There is more delving that needs to be done:

* What constitutes moderately hazardous? How does the toxicity of these chemicals vary?
* How does the application amount of each chemical relate to the lethal dose(if it exists) for that chemical? How long before it is no longer fatal?
* What is the environmental impact of these chemicals. Those that aren't toxic to humans could well be toxic to other animals. In fact while looking at the toxicity, I found that several of these chemicals are severely, acutely toxic to aquatic life which is a big problem if the pesticides get swept into local water bodies. 
